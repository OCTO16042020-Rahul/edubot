{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "def answerfromwiki(text): \n",
    "    complete_content = wikipedia.summary(text)\n",
    "    print(complete_content)\n",
    "    return complete_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ningesh\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Ningesh\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Ningesh\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Ningesh\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Ningesh\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Ningesh\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdf5 is not supported on this machine (please install/reinstall h5py for optimal experience)\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From C:\\Users\\Ningesh\\Anaconda3\\lib\\site-packages\\tflearn\\helpers\\summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ningesh\\Anaconda3\\lib\\site-packages\\tflearn\\helpers\\trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ningesh\\Anaconda3\\lib\\site-packages\\tflearn\\collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ningesh\\Anaconda3\\lib\\site-packages\\tflearn\\config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ningesh\\Anaconda3\\lib\\site-packages\\tflearn\\config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ningesh\\Anaconda3\\lib\\site-packages\\tflearn\\config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ningesh\\Anaconda3\\lib\\site-packages\\tflearn\\layers\\core.py:81: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ningesh\\Anaconda3\\lib\\site-packages\\tflearn\\optimizers.py:238: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ningesh\\Anaconda3\\lib\\site-packages\\tflearn\\summaries.py:46: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ningesh\\Anaconda3\\lib\\site-packages\\tflearn\\helpers\\trainer.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Ningesh\\063AutoQA\\model.tflearn\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Ningesh\\063AutoQA\\model.tflearn\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [23/Jun/2020 11:33:44] \"\u001b[37mGET /static/digital.mp4 HTTP/1.1\u001b[0m\" 206 -\n",
      "127.0.0.1 - - [23/Jun/2020 11:33:44] \"\u001b[37mGET /static/digital.mp4 HTTP/1.1\u001b[0m\" 206 -\n",
      "127.0.0.1 - - [23/Jun/2020 11:33:45] \"\u001b[37mGET /static/digital.mp4 HTTP/1.1\u001b[0m\" 206 -\n",
      "127.0.0.1 - - [23/Jun/2020 11:33:45] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [23/Jun/2020 11:33:47] \"\u001b[33mGET /static/images/banner.png HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [23/Jun/2020 11:33:53] \"\u001b[32mPOST /login HTTP/1.1\u001b[0m\" 302 -\n",
      "127.0.0.1 - - [23/Jun/2020 11:33:53] \"\u001b[37mGET /chatbot HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [23/Jun/2020 11:33:54] \"\u001b[37mGET /static/digital.mp4 HTTP/1.1\u001b[0m\" 206 -\n",
      "127.0.0.1 - - [23/Jun/2020 11:33:55] \"\u001b[37mGET /static/digital.mp4 HTTP/1.1\u001b[0m\" 206 -\n",
      "127.0.0.1 - - [23/Jun/2020 11:34:27] \"\u001b[37mGET /get?msg=nlp HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.35677327e-25 4.82713767e-21 4.18832297e-15 7.27169269e-31\n",
      "  6.23853134e-24 7.16293802e-10 4.48972990e-23 7.61878326e-30\n",
      "  7.82194291e-25 1.78971524e-25 9.35926938e-28 5.85414220e-25\n",
      "  7.91802635e-36 9.54509477e-22 3.22457007e-14 3.57087703e-16\n",
      "  1.59873756e-32 4.06398904e-36 1.66081281e-11 2.27508690e-06\n",
      "  1.88370261e-12 2.70327574e-16 6.35801088e-16 1.53898164e-24\n",
      "  1.76671872e-19 2.59847937e-28 3.89788858e-23 1.61730319e-12\n",
      "  2.11121211e-20 6.41645986e-17 1.26033118e-34 2.91965206e-30\n",
      "  1.59042507e-21 1.68020351e-19 7.62909791e-10 5.51623134e-15\n",
      "  1.37015160e-24 2.23123493e-07 1.87126378e-29 7.40857842e-32\n",
      "  4.41759123e-32 1.68671053e-32 3.27190809e-11 2.50775233e-24\n",
      "  5.80504691e-23 1.13738344e-23 5.24850413e-16 3.02897748e-33\n",
      "  5.14671100e-32 1.15111076e-16 5.59103293e-31 1.45994611e-21\n",
      "  1.44029652e-15 2.87273252e-07 1.08167244e-26 6.24564952e-32\n",
      "  7.19293005e-30 6.72095019e-11 4.60437403e-25 6.72542910e-10\n",
      "  3.38718973e-16 1.47921599e-14 4.54922731e-11 1.35638176e-08\n",
      "  4.74105320e-07 4.11619254e-07 1.74004788e-12 2.09513244e-14\n",
      "  1.13633015e-22 9.26125714e-33 1.48940978e-23 2.88312396e-18\n",
      "  1.44262509e-19 1.14452246e-06 5.90310549e-07 1.70777008e-19\n",
      "  1.01405078e-32 2.96085516e-18 6.84356241e-24 2.56167632e-31\n",
      "  1.92383368e-07 1.52212092e-08 4.57628206e-12 4.24866618e-16\n",
      "  1.40726444e-08 3.88566092e-28 1.80741335e-06 4.16442275e-24\n",
      "  9.99992251e-01 2.69762211e-07 8.61718889e-15 5.94633011e-18\n",
      "  8.11609024e-16 2.57429420e-08 1.62709513e-13 3.08756211e-12]]\n",
      "88\n",
      "0.99999225\n",
      "Natural Language Processing or NLP is an automated way to understand or analyze the natural languages and extract required information from such data by applying machine learning Algorithms.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Jun/2020 11:34:53] \"\u001b[37mGET /get?msg=DigitalImage%20Forensics HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.4754081e-05 2.0472466e-11 7.9068978e-38 6.0981547e-06 6.9183111e-04\n",
      "  4.2197177e-22 9.3462070e-18 2.5099310e-01 9.4547155e-26 9.1673716e-30\n",
      "  1.5018545e-18 6.7265613e-32 9.7744701e-11 5.8672263e-20 3.6912866e-30\n",
      "  9.8311355e-16 9.7485557e-03 1.4550454e-06 2.1289685e-35 2.5253260e-31\n",
      "  3.5886764e-32 3.0228448e-32 1.1817690e-09 6.9323098e-16 7.8457394e-27\n",
      "  1.5481959e-07 5.6523486e-26 3.2996373e-28 5.1661191e-05 2.8763697e-36\n",
      "  1.3343537e-14 4.5383491e-16 3.1194955e-10 3.7673457e-18 3.6917625e-24\n",
      "  4.8905593e-12 3.0865952e-02 4.5801571e-32 1.6970798e-24 5.8505459e-15\n",
      "  6.9343871e-12 1.5611804e-04 3.8290353e-27 4.3375834e-08 1.3341400e-29\n",
      "  3.3729990e-32 7.8382800e-22 3.2154023e-21 8.4575437e-20 1.2648715e-33\n",
      "  2.8907463e-10 2.6832548e-18 1.2949428e-08 2.8731990e-22 2.7853030e-08\n",
      "  1.1186136e-21 1.2398792e-07 1.7627757e-36 2.5472292e-17 2.0383361e-22\n",
      "  4.0280123e-14 2.5552091e-10 1.2459477e-15 4.1591321e-15 4.0419531e-20\n",
      "  0.0000000e+00 0.0000000e+00 3.1055684e-21 5.1165432e-22 1.4317180e-08\n",
      "  1.0996666e-30 1.9783309e-29 4.9810433e-21 1.5870612e-33 3.7991246e-33\n",
      "  4.6543874e-21 7.0739740e-01 2.4057593e-25 1.8020208e-05 3.3361709e-09\n",
      "  1.6731497e-37 2.5348903e-24 1.4387758e-26 1.3160978e-16 5.5790856e-26\n",
      "  5.8273440e-20 8.8059940e-22 2.4583767e-05 1.1949577e-29 1.4185498e-21\n",
      "  3.7934189e-18 3.0160190e-14 4.5033896e-17 1.0276220e-36 3.1443205e-37\n",
      "  2.7618316e-15]]\n",
      "76\n",
      "0.7073974\n",
      "Stemming is basically removing the suffix from a word and reduce it to its root word. For example: “Flying” is a word and its suffix is “ing”, if we remove “ing” from “Flying” then we will get base word or root word which is “Fly”. We uses these suffix to create a new word from original stem word. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Jun/2020 11:35:11] \"\u001b[37mGET /get?msg=what%20is%20Digital%20Image%20Forensics HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.0150344e-08 1.9509662e-25 0.0000000e+00 1.8199347e-20 6.3481734e-13\n",
      "  0.0000000e+00 3.5459199e-33 9.9998724e-01 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 6.8616382e-33 0.0000000e+00 0.0000000e+00\n",
      "  6.4633734e-32 1.1316261e-08 7.0904572e-16 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.9875436e-23 1.9068746e-28 0.0000000e+00\n",
      "  1.0186317e-18 0.0000000e+00 0.0000000e+00 2.9897876e-07 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 2.2407069e-31 0.0000000e+00 0.0000000e+00\n",
      "  3.5038033e-20 4.0691947e-07 0.0000000e+00 0.0000000e+00 2.7173141e-30\n",
      "  1.7329365e-25 1.0255822e-06 0.0000000e+00 6.2946461e-11 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.1709392e-31 0.0000000e+00 2.1088935e-18 0.0000000e+00 3.8117668e-20\n",
      "  0.0000000e+00 2.3628834e-27 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.8883421e-38 8.9820076e-30 2.0422044e-30 2.1269900e-34 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.8730808e-31\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 1.0805444e-05 0.0000000e+00 1.6928910e-24 1.5464054e-18\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 8.6120167e-08 0.0000000e+00 0.0000000e+00\n",
      "  5.1090002e-36 4.5316722e-24 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00]]\n",
      "7\n",
      "0.99998724\n",
      "the extraction and analysis of digitally acquired photographic images to validate their authenticity by recovering the metadata of the image file to ascertain its history.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Jun/2020 11:35:42] \"\u001b[37mGET /chatbot HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [23/Jun/2020 11:35:42] \"\u001b[37mGET /static/digital.mp4 HTTP/1.1\u001b[0m\" 206 -\n",
      "127.0.0.1 - - [23/Jun/2020 11:35:43] \"\u001b[37mGET /static/digital.mp4 HTTP/1.1\u001b[0m\" 206 -\n",
      "127.0.0.1 - - [23/Jun/2020 11:35:47] \"\u001b[37mGET /static/digital.mp4 HTTP/1.1\u001b[0m\" 206 -\n",
      "127.0.0.1 - - [23/Jun/2020 11:35:47] \"\u001b[37mGET /static/digital.mp4 HTTP/1.1\u001b[0m\" 206 -\n",
      "127.0.0.1 - - [23/Jun/2020 11:35:48] \"\u001b[37mGET /static/digital.mp4 HTTP/1.1\u001b[0m\" 206 -\n",
      "127.0.0.1 - - [23/Jun/2020 11:35:50] \"\u001b[37mGET /static/digital.mp4 HTTP/1.1\u001b[0m\" 206 -\n",
      "127.0.0.1 - - [23/Jun/2020 11:35:51] \"\u001b[37mGET /static/digital.mp4 HTTP/1.1\u001b[0m\" 206 -\n",
      "127.0.0.1 - - [23/Jun/2020 11:36:09] \"\u001b[37mGET /get?msg=Digital%20Image%20Forensics HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.2298519e-08 1.3462278e-26 0.0000000e+00 1.7030825e-20 7.0582673e-14\n",
      "  0.0000000e+00 4.0588299e-33 9.9999070e-01 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 3.9751358e-33 0.0000000e+00 0.0000000e+00\n",
      "  4.0825889e-33 1.8871882e-08 1.5752780e-15 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 2.9785706e-24 1.0365319e-28 0.0000000e+00\n",
      "  2.2668903e-19 0.0000000e+00 0.0000000e+00 8.7061863e-08 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 5.5462633e-32 0.0000000e+00 0.0000000e+00\n",
      "  1.0504040e-20 1.5214225e-07 0.0000000e+00 0.0000000e+00 4.4622345e-30\n",
      "  1.1884912e-25 1.4629209e-06 0.0000000e+00 5.0922138e-11 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.4294722e-31 0.0000000e+00 1.2459025e-19 0.0000000e+00 5.0025260e-20\n",
      "  0.0000000e+00 2.9590965e-28 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 2.9380473e-31 1.1782809e-31 7.1835196e-36 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 8.5355401e-32\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 7.5972716e-06 0.0000000e+00 1.8868623e-25 4.3463738e-18\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 2.4516867e-08 0.0000000e+00 0.0000000e+00\n",
      "  1.6618094e-36 9.2788926e-25 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00]]\n",
      "7\n",
      "0.9999907\n",
      "the extraction and analysis of digitally acquired photographic images to validate their authenticity by recovering the metadata of the image file to ascertain its history.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Jun/2020 11:36:20] \"\u001b[37mGET /get?msg=what%20is%20Digital%20Evidences HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.4919912e-30 2.7289496e-13 0.0000000e+00 1.7519125e-28 2.9984307e-19\n",
      "  1.4159407e-29 1.0238346e-24 2.2258949e-16 3.6359918e-08 1.3613234e-13\n",
      "  1.3861470e-05 5.0734546e-33 2.1996943e-08 2.7849204e-08 9.0109181e-22\n",
      "  2.6595970e-18 4.1181604e-20 6.1907124e-10 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 7.2425332e-26 0.0000000e+00 5.2387475e-07 0.0000000e+00\n",
      "  3.1296565e-06 1.4315129e-12 0.0000000e+00 1.6662368e-28 6.7569380e-27\n",
      "  7.6319452e-19 1.4688130e-19 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.0686534e-38 4.9602124e-29 0.0000000e+00 2.6839351e-18 3.5306364e-08\n",
      "  9.9998093e-01 1.4248868e-06 1.3652946e-31 2.2865658e-19 0.0000000e+00\n",
      "  1.2982512e-20 1.6825264e-18 1.3409611e-11 9.5243851e-25 0.0000000e+00\n",
      "  3.9930650e-31 3.9500887e-21 3.3129335e-30 0.0000000e+00 1.1603941e-34\n",
      "  5.4491904e-26 5.0779524e-12 1.0948845e-37 0.0000000e+00 0.0000000e+00\n",
      "  4.1878072e-25 0.0000000e+00 2.4052203e-34 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 7.5975603e-32 0.0000000e+00 3.9410261e-22\n",
      "  8.6782596e-28 7.0089885e-22 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  3.2741651e-13 2.0830715e-10 0.0000000e+00 2.0616553e-33 9.7433112e-22\n",
      "  0.0000000e+00 1.0971481e-34 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.9556133e-37 0.0000000e+00 2.8954718e-12 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 2.4113192e-20 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00]]\n",
      "40\n",
      "0.9999809\n",
      "encompasses any or all digital data to an investigation that is stored on, recieved by, or transmited by electronic device• Evidence can be that data from which investigator can find a crime has been committed or not.• The digital data can provide a link between a crime and its victim or a crime and its perpetrator.• Digital Evidences can be extracted from Volatile Memory: (RAM data),Non-volatile Memory (Disk data)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Jun/2020 11:36:28] \"\u001b[37mGET /chatbot HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [23/Jun/2020 11:36:35] \"\u001b[37mGET /static/digital.mp4 HTTP/1.1\u001b[0m\" 206 -\n",
      "127.0.0.1 - - [23/Jun/2020 11:36:35] \"\u001b[37mGET /static/digital.mp4 HTTP/1.1\u001b[0m\" 206 -\n",
      "127.0.0.1 - - [23/Jun/2020 11:36:35] \"\u001b[37mGET /static/digital.mp4 HTTP/1.1\u001b[0m\" 206 -\n",
      "127.0.0.1 - - [23/Jun/2020 11:36:36] \"\u001b[37mGET /static/digital.mp4 HTTP/1.1\u001b[0m\" 206 -\n",
      "127.0.0.1 - - [23/Jun/2020 11:36:36] \"\u001b[37mGET /static/digital.mp4 HTTP/1.1\u001b[0m\" 206 -\n",
      "127.0.0.1 - - [23/Jun/2020 11:36:36] \"\u001b[37mGET /static/digital.mp4 HTTP/1.1\u001b[0m\" 206 -\n",
      "127.0.0.1 - - [23/Jun/2020 11:36:45] \"\u001b[37mGET /get?msg=what%20is%20Digital%20Image%20Forensics HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.0150344e-08 1.9509662e-25 0.0000000e+00 1.8199347e-20 6.3481734e-13\n",
      "  0.0000000e+00 3.5459199e-33 9.9998724e-01 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 6.8616382e-33 0.0000000e+00 0.0000000e+00\n",
      "  6.4633734e-32 1.1316261e-08 7.0904572e-16 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.9875436e-23 1.9068746e-28 0.0000000e+00\n",
      "  1.0186317e-18 0.0000000e+00 0.0000000e+00 2.9897876e-07 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 2.2407069e-31 0.0000000e+00 0.0000000e+00\n",
      "  3.5038033e-20 4.0691947e-07 0.0000000e+00 0.0000000e+00 2.7173141e-30\n",
      "  1.7329365e-25 1.0255822e-06 0.0000000e+00 6.2946461e-11 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.1709392e-31 0.0000000e+00 2.1088935e-18 0.0000000e+00 3.8117668e-20\n",
      "  0.0000000e+00 2.3628834e-27 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.8883421e-38 8.9820076e-30 2.0422044e-30 2.1269900e-34 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.8730808e-31\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 1.0805444e-05 0.0000000e+00 1.6928910e-24 1.5464054e-18\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 8.6120167e-08 0.0000000e+00 0.0000000e+00\n",
      "  5.1090002e-36 4.5316722e-24 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00]]\n",
      "7\n",
      "0.99998724\n",
      "the extraction and analysis of digitally acquired photographic images to validate their authenticity by recovering the metadata of the image file to ascertain its history.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Jun/2020 11:37:17] \"\u001b[37mGET /get?msg=what%20is%20Digital%20Video%2FAudio%20Forensics HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.6197793e-19 7.3238814e-21 0.0000000e+00 8.0250467e-28 2.2625149e-21\n",
      "  0.0000000e+00 3.7135005e-22 8.2421252e-07 4.9918422e-29 0.0000000e+00\n",
      "  1.0911174e-28 0.0000000e+00 3.7231642e-20 7.2907030e-23 0.0000000e+00\n",
      "  3.1298093e-25 1.4823623e-13 5.1255228e-08 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 2.5676468e-09 0.0000000e+00\n",
      "  9.7883377e-12 1.2924377e-26 0.0000000e+00 1.8216349e-19 0.0000000e+00\n",
      "  4.4973844e-29 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.2109811e-29 2.5654855e-22 0.0000000e+00 2.3006048e-32 1.5566251e-10\n",
      "  1.7131077e-06 9.9999738e-01 0.0000000e+00 1.6060867e-10 0.0000000e+00\n",
      "  0.0000000e+00 7.4740907e-28 7.0851483e-31 1.2688998e-35 0.0000000e+00\n",
      "  8.3363350e-34 0.0000000e+00 5.7201387e-30 0.0000000e+00 3.2576616e-28\n",
      "  0.0000000e+00 1.4638774e-24 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 2.2583682e-35 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.5858202e-32 0.0000000e+00 1.9839803e-31\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  3.8096211e-37 3.9985274e-08 0.0000000e+00 0.0000000e+00 5.9045074e-15\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 4.1651766e-08 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 7.3987521e-19 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00]]\n",
      "41\n",
      "0.9999974\n",
      "the collection, analysis and evaluation of sound and video recordings. The science is the establishment of authenticity as to whether a recording is original and whether it has been tampered with, either maliciously or accidentally\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Jun/2020 11:37:43] \"\u001b[37mGET /static/digital.mp4 HTTP/1.1\u001b[0m\" 206 -\n",
      "127.0.0.1 - - [23/Jun/2020 11:37:43] \"\u001b[37mGET /static/digital.mp4 HTTP/1.1\u001b[0m\" 206 -\n",
      "127.0.0.1 - - [23/Jun/2020 11:37:44] \"\u001b[37mGET /static/digital.mp4 HTTP/1.1\u001b[0m\" 206 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request, session, url_for, redirect, jsonify\n",
    "import pymysql\n",
    "\n",
    "#=========\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "stemmer = LancasterStemmer()\n",
    "import numpy\n",
    "import tflearn\n",
    "import tensorflow\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import scipy.spatial\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import math\n",
    "import warnings\n",
    "import sys\n",
    "#from sklearn.utils.extmath import np.dot\n",
    "\n",
    "#=========Database Connection===\n",
    "connection = pymysql.connect(host=\"localhost\", user=\"root\", password=\"\", database=\"063autoqa\")\n",
    "cursor = connection.cursor()\n",
    "#============start=======chatbot============\n",
    "#chatbot\n",
    "with open(\"QASystemCrypto.json\", encoding=\"utf8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "try:\n",
    "    with open(\"data.pickle\", \"rb\") as f:\n",
    "        words, labels, training, output = pickle.load(f)\n",
    "except:\n",
    "    words = []\n",
    "    labels = []\n",
    "    docs_x = []\n",
    "    docs_y = []\n",
    "\n",
    "    for intent in data[\"intents\"]:\n",
    "        for pattern in intent[\"patterns\"]:\n",
    "            wrds = nltk.word_tokenize(pattern)\n",
    "            words.extend(wrds)\n",
    "            docs_x.append(wrds)\n",
    "            # print(wrds)\n",
    "            docs_y.append(intent[\"tag\"])\n",
    "\n",
    "        if intent[\"tag\"] not in labels:\n",
    "            labels.append(intent[\"tag\"])\n",
    "\n",
    "    words = [stemmer.stem(w.lower()) for w in words if w != \"?\"]\n",
    "    words = sorted(list(set(words)))\n",
    "\n",
    "    labels = sorted(labels)\n",
    "\n",
    "    training = []\n",
    "    output = []\n",
    "\n",
    "    out_empty = [0 for _ in range(len(labels))]\n",
    "\n",
    "    for x, doc in enumerate(docs_x):\n",
    "        bag = []\n",
    "\n",
    "        wrds = [stemmer.stem(w.lower()) for w in doc]\n",
    "\n",
    "        for w in words:\n",
    "            if w in wrds:\n",
    "                bag.append(1)\n",
    "            else:\n",
    "                bag.append(0)\n",
    "\n",
    "        output_row = out_empty[:]\n",
    "        output_row[labels.index(docs_y[x])] = 1\n",
    "\n",
    "        training.append(bag)\n",
    "        output.append(output_row)\n",
    "\n",
    "    training = numpy.array(training)\n",
    "    output = numpy.array(output)\n",
    "\n",
    "    with open(\"data.pickle\", \"wb\") as f:\n",
    "        pickle.dump((words, labels, training, output), f)\n",
    "\n",
    "tensorflow.reset_default_graph()\n",
    "\n",
    "net = tflearn.input_data(shape=[None, len(training[0])])\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, len(output[0]), activation=\"softmax\")\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "model11 = tflearn.DNN(net)\n",
    "\n",
    "try:\n",
    "    model11.load(\"model.tflearn\")\n",
    "except:\n",
    "\n",
    "    model11.fit(training, output, n_epoch=1000, batch_size=8, show_metric=True)\n",
    "    model11.save(\"model.tflearn\")\n",
    "\n",
    "\n",
    "#==============end====chatbot=================\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.secret_key = 'random string'\n",
    "\n",
    "\n",
    "@app.route('/index')\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "\n",
    "@app.route('/register', methods=[\"GET\",\"POST\"])\n",
    "def register():\n",
    "    if request.method == \"POST\":\n",
    "        name = request.form.get(\"name\")\n",
    "        email = request.form.get(\"email\")\n",
    "        mobile = request.form.get(\"mobile\")\n",
    "        gender = request.form.get(\"gender\")\n",
    "        dob = request.form.get(\"dob\")\n",
    "        username = request.form.get(\"username\")\n",
    "        password = request.form.get(\"password\")\n",
    "        cursor.execute(\"insert into userdetails(fullname,gender,mobile,email,dob,username,password) values('\"+name+\"','\"+gender+\"','\"+mobile+\"','\"+email+\"','\"+dob+\"','\"+username+\"','\"+password+\"')\")\n",
    "        connection.commit()\n",
    "        #return render_template('/index')\n",
    "        return render_template('index.html')\n",
    "    else:\n",
    "        #return render_template('index.html')\n",
    "        return render_template('index.html')\n",
    "\n",
    "\n",
    "@app.route('/login', methods=[\"GET\",\"POST\"])\n",
    "def login():\n",
    "    msg = ''\n",
    "    if request.method == \"POST\":\n",
    "        session.pop('user',None)\n",
    "        username = request.form.get(\"username\")\n",
    "        password = request.form.get(\"password\")\n",
    "        cursor.execute('SELECT * FROM userdetails WHERE username = %s AND password = %s', (username, password))\n",
    "        account = cursor.fetchone()\n",
    "        #print(account)\n",
    "        if account:\n",
    "            session['user'] = account[1]\n",
    "            #return render_template('home.html')\n",
    "            return redirect(url_for('chatbot'))\n",
    "        else:\n",
    "            # Account doesnt exist or username/password incorrect\n",
    "            msg = 'Incorrect username/password!'\n",
    "    #return render_template('index.html', msg=msg)\n",
    "    return redirect(url_for('index'))\n",
    "\n",
    "\n",
    "#logout code\n",
    "@app.route('/logout')\n",
    "def logout():\n",
    "    session.pop('user')\n",
    "    return redirect(url_for('index'))\n",
    "\n",
    "\n",
    "@app.route('/home')\n",
    "def home():\n",
    "    if 'user' in session:\n",
    "        return render_template('home.html', user=session['user'])\n",
    "    return redirect(url_for('index'))\n",
    "\n",
    "@app.route('/aboutus')\n",
    "def aboutus():\n",
    "    return render_template('aboutus.html')\n",
    "\n",
    "\n",
    "@app.route('/contactus')\n",
    "def contactus():\n",
    "    return render_template('contactus.html')\n",
    "#bot start======\n",
    "\n",
    "@app.route('/chatbot')\n",
    "def chatbot():\n",
    "    if 'user' in session:\n",
    "        return render_template('chatbot.html', user=session['user'])\n",
    "    return redirect(url_for('index'))\n",
    "\n",
    "\n",
    "@app.route(\"/get\")\n",
    "def get_bot_response():\n",
    "    userText = request.args.get('msg')\n",
    "    results = model11.predict([bag_of_words(userText, words)])\n",
    "    print(results)\n",
    "    results_index = numpy.argmax(results)\n",
    "    print(results_index)\n",
    "    print(results[0][results_index])\n",
    "    oppred=results[0][results_index]\n",
    "    outdatagot = \"No data found for this query in our dataset \\n\"\n",
    "    if oppred>0.7:\n",
    "        tag = labels[results_index]\n",
    "        #outdatagot = \"\"\n",
    "        for tg in data[\"intents\"]:\n",
    "            if tg['tag'] == tag:\n",
    "                responses = tg['responses']\n",
    "                outdatagot = random.choice(responses)\n",
    "                print(outdatagot)\n",
    "        return str(outdatagot)\n",
    "    else:\n",
    "        outdatagot=outdatagot+\" Answer from wikipedia \\n\"+answerfromwiki(userText)\n",
    "        return str(outdatagot)\n",
    "\n",
    "\n",
    "def bag_of_words(s, words):\n",
    "    bag = [0 for _ in range(len(words))]\n",
    "    s_words = nltk.word_tokenize(s)\n",
    "    s_words = [stemmer.stem(word.lower()) for word in s_words]\n",
    "    for se in s_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == se:\n",
    "                bag[i] = 1\n",
    "    return numpy.array(bag)\n",
    "model11.load(\"model.tflearn\")\n",
    "#bot end======-------------\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #app.run(debug=\"True\")\n",
    "    app.run('0.0.0.0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
